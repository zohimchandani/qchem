{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/qc1/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from IPython.display import SVG\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.quantum_info import Statevector\n",
    "from qiskit.circuit import Parameter, ParameterVector\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier, VQC\n",
    "from qiskit_machine_learning.algorithms.regressors import NeuralNetworkRegressor, VQR\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
    "from qiskit_machine_learning.utils.loss_functions.loss_functions import CrossEntropyLoss\n",
    "from qiskit_algorithms.optimizers import COBYLA, L_BFGS_B\n",
    "from qiskit.circuit.library import Initialize\n",
    "import matplotlib.pyplot as plt\n",
    "import deepchem as dc\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 4096)\n",
      "[ 181 1488]\n",
      "[ 136 1025]\n",
      "[121 939]\n",
      "[  3 581]\n",
      "[1369 1475]\n",
      "[ 646 1034]\n",
      "[ 71 638]\n",
      "[128 991]\n",
      "[109 866]\n",
      "[ 139 1043]\n",
      "[ 108 1436]\n",
      "[ 161 1284]\n",
      "[127 984]\n",
      "[123 232]\n",
      "[ 164 1303]\n",
      "[1248 1362]\n",
      "[ 152 1225]\n",
      "[ 137 1030]\n",
      "[ 590 1050]\n",
      "[463 684 959]\n",
      "[  35 1143]\n",
      "[ 955 1214]\n",
      "[ 15  32 158 458]\n",
      "[ 672 1020]\n",
      "[298 843]\n",
      "[ 22 336]\n",
      "[326 357]\n",
      "[124 286]\n",
      "[687 689]\n",
      "[  50 1130]\n",
      "[  51 1241]\n",
      "[ 385 1217]\n",
      "[ 383 1173]\n",
      "[ 932 1412]\n",
      "[ 626 1413]\n",
      "[ 122 1411]\n",
      "[ 60 126]\n",
      "[ 468 1005]\n",
      "[ 986 1294]\n",
      "[ 37 140]\n",
      "[ 97 781]\n",
      "[1394 1474]\n",
      "[ 796 1341]\n",
      "[39 68]\n",
      "[284 370]\n",
      "[ 369 1009]\n"
     ]
    }
   ],
   "source": [
    "num_qubits = 12\n",
    "fpgen = rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=2**num_qubits)\n",
    "# fpgen = rdFingerprintGenerator.GetMorganGenerator(radius=5, includeChirality=True, fpSize=2**num_qubits)\n",
    "# fpgen = rdFingerprintGenerator.GetAtomPairGenerator(fpSize=2**num_qubits, includeChirality=True)\n",
    "df = pd.read_csv('bace.csv')\n",
    "df_smiles = df['mol'].to_numpy()\n",
    "df_morgan = np.zeros([len(df_smiles), 2**num_qubits])\n",
    "df_classes = df['Class'].to_numpy()\n",
    "df_classes = df_classes + 1\n",
    "for i in range(len(df_smiles)):\n",
    "    mol = Chem.MolFromSmiles(df_smiles[i])\n",
    "    fp = fpgen.GetFingerprint(mol)\n",
    "    array = np.zeros((0, ))\n",
    "    DataStructs.ConvertToNumpyArray(fp, array)\n",
    "    # array = array / np.linalg.norm(array)\n",
    "    df_morgan[i] = array\n",
    "unq, count = np.unique(df_morgan, axis=0, return_counts=True)\n",
    "repeated_groups = unq[count > 1]\n",
    "print(repeated_groups.shape)\n",
    "for repeated_group in repeated_groups:\n",
    "    repeated_idx = np.argwhere(np.all(df_morgan == repeated_group, axis=1))\n",
    "    print(repeated_idx.ravel())\n",
    "\n",
    "dataset = dc.data.DiskDataset.from_numpy(X=df_classes,ids=df_smiles)\n",
    "scaffoldsplitter = dc.splits.ScaffoldSplitter()\n",
    "train, valid, test = scaffoldsplitter.train_valid_test_split(dataset)\n",
    "train_classes = train.X\n",
    "valid_classes = valid.X\n",
    "test_classes = test.X\n",
    "train_smiles = train.ids\n",
    "valid_smiles = valid.ids\n",
    "test_smiles = test.ids\n",
    "train_num = len(train_smiles)\n",
    "valid_num = len(valid_smiles)\n",
    "test_num = len(test_smiles)\n",
    "df_train_morgan = np.zeros([train_num, 2**num_qubits])\n",
    "df_valid_morgan = np.zeros([valid_num, 2**num_qubits])\n",
    "df_test_morgan = np.zeros([test_num, 2**num_qubits])\n",
    "for i in range(train_num):\n",
    "    mol = Chem.MolFromSmiles(train_smiles[i])\n",
    "    fp = fpgen.GetFingerprint(mol)\n",
    "    array = np.zeros((0, ))\n",
    "    DataStructs.ConvertToNumpyArray(fp, array)\n",
    "    # array = array / np.linalg.norm(array)\n",
    "    df_train_morgan[i] = array\n",
    "for i in range(valid_num):\n",
    "    mol = Chem.MolFromSmiles(valid_smiles[i])\n",
    "    fp = fpgen.GetFingerprint(mol)\n",
    "    array = np.zeros((0, ))\n",
    "    DataStructs.ConvertToNumpyArray(fp, array)\n",
    "    # array = array / np.linalg.norm(array)\n",
    "    df_valid_morgan[i] = array\n",
    "for i in range(test_num):\n",
    "    mol = Chem.MolFromSmiles(test_smiles[i])\n",
    "    fp = fpgen.GetFingerprint(mol)\n",
    "    array = np.zeros((0, ))\n",
    "    DataStructs.ConvertToNumpyArray(fp, array)\n",
    "    # array = array / np.linalg.norm(array)\n",
    "    df_test_morgan[i] = array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_qubits = 2\n",
    "df_combined = np.concatenate([df_train_morgan, df_valid_morgan, df_test_morgan], axis=0)\n",
    "pca = PCA(n_components=2**reduced_qubits, random_state=53,  svd_solver='full')\n",
    "pca_combined = pca.fit_transform(df_combined)\n",
    "pca_combined = normalize(pca_combined, norm='l2', axis=1)\n",
    "pca_train = pca_combined[:train_num]\n",
    "pca_valid = pca_combined[train_num:train_num+valid_num]\n",
    "pca_test = pca_combined[train_num+valid_num:]\n",
    "\n",
    "n = 0\n",
    "for i in range(len(train_smiles)):\n",
    "    for j in range(2**reduced_qubits):\n",
    "        if pca_train[i,j] != 0:\n",
    "            if n == 0:\n",
    "                df_pca_con_train_morgan = pca_train[i,j]\n",
    "                df_pca_con_train_indices = np.array([i,j], dtype=int)\n",
    "                n = n + 1\n",
    "            else:\n",
    "                df_pca_con_train_morgan = np.append(df_pca_con_train_morgan, pca_train[i,j])\n",
    "                df_pca_con_train_indices = np.append(df_pca_con_train_indices, np.array([i,j]))\n",
    "n = 0\n",
    "for i in range(len(valid_smiles)):\n",
    "    for j in range(2**reduced_qubits):\n",
    "        if pca_valid[i,j] != 0:\n",
    "            if n == 0:\n",
    "                df_pca_con_valid_morgan = pca_valid[i,j]\n",
    "                df_pca_con_valid_indices = np.array([i,j], dtype=int)\n",
    "                n = n + 1\n",
    "            else:\n",
    "                df_pca_con_valid_morgan = np.append(df_pca_con_valid_morgan, pca_valid[i,j])\n",
    "                df_pca_con_valid_indices = np.append(df_pca_con_valid_indices, np.array([i,j]))\n",
    "n = 0\n",
    "for i in range(len(test_smiles)):\n",
    "    for j in range(2**reduced_qubits):\n",
    "        if pca_test[i,j] != 0:\n",
    "            if n == 0:\n",
    "                df_pca_con_test_morgan = pca_test[i,j]\n",
    "                df_pca_con_test_indices = np.array([i,j], dtype=int)\n",
    "                n = n + 1\n",
    "            else:\n",
    "                df_pca_con_test_morgan = np.append(df_pca_con_test_morgan, pca_test[i,j])\n",
    "                df_pca_con_test_indices = np.append(df_pca_con_test_indices, np.array([i,j]))\n",
    "\n",
    "\n",
    "\n",
    "df_pca_con_train_morgan = df_pca_con_train_morgan.T\n",
    "df_pca_con_valid_morgan = df_pca_con_valid_morgan.T\n",
    "df_pca_con_test_morgan = df_pca_con_test_morgan.T\n",
    "df_pca_con_train_indices = df_pca_con_train_indices + 1\n",
    "df_pca_con_valid_indices = df_pca_con_valid_indices + 1\n",
    "df_pca_con_test_indices = df_pca_con_test_indices + 1\n",
    "df_pca_new_con_train_indices = np.reshape(df_pca_con_train_indices, (-1,2))\n",
    "df_pca_new_con_valid_indices = np.reshape(df_pca_con_valid_indices, (-1,2))\n",
    "df_pca_new_con_test_indices = np.reshape(df_pca_con_test_indices, (-1,2))\n",
    "df_train_input = np.zeros([len(train_smiles),1])\n",
    "df_valid_input = np.zeros([len(valid_smiles),1])\n",
    "df_test_input = np.zeros([len(test_smiles),1])\n",
    "\n",
    "newpath = f'/Users/choyboy/Documents/Python/QML/bace_dataset_topol_split/bace_pca_{num_qubits}q{reduced_qubits}'\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "np.savetxt(f'{newpath}/qc_pca_train_initial_bace_{num_qubits}q{reduced_qubits}', df_pca_con_train_morgan, delimiter='\\t')\n",
    "np.savetxt(f'{newpath}/qc_pca_train_initial_index_bace_{num_qubits}q{reduced_qubits}', df_pca_new_con_train_indices.astype(int), fmt='%s', delimiter='\\t')\n",
    "np.savetxt(f'{newpath}/qc_pca_train_classes_bace_{num_qubits}q{reduced_qubits}', train_classes, fmt='%s', delimiter='\\t')\n",
    "np.savetxt(f'{newpath}/qc_pca_train_input_bace_{num_qubits}q{reduced_qubits}', df_train_input, delimiter='\\t')\n",
    "np.savetxt(f'{newpath}/qc_pca_valid_initial_bace_{num_qubits}q{reduced_qubits}', df_pca_con_valid_morgan, delimiter='\\t')\n",
    "np.savetxt(f'{newpath}/qc_pca_valid_initial_index_bace_{num_qubits}q{reduced_qubits}', df_pca_new_con_valid_indices.astype(int), fmt='%s', delimiter='\\t')\n",
    "np.savetxt(f'{newpath}/qc_pca_valid_classes_bace_{num_qubits}q{reduced_qubits}', valid_classes, fmt='%s', delimiter='\\t')\n",
    "np.savetxt(f'{newpath}/qc_pca_valid_input_bace_{num_qubits}q{reduced_qubits}', df_valid_input, delimiter='\\t')\n",
    "np.savetxt(f'{newpath}/qc_pca_test_initial_bace_{num_qubits}q{reduced_qubits}', df_pca_con_test_morgan, delimiter='\\t')\n",
    "np.savetxt(f'{newpath}/qc_pca_test_initial_index_bace_{num_qubits}q{reduced_qubits}', df_pca_new_con_test_indices.astype(int), fmt='%s', delimiter='\\t')\n",
    "np.savetxt(f'{newpath}/qc_pca_test_classes_bace_{num_qubits}q{reduced_qubits}', test_classes, fmt='%s', delimiter='\\t')\n",
    "np.savetxt(f'{newpath}/qc_pca_test_input_bace_{num_qubits}q{reduced_qubits}', df_test_input, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_qubits = 2\n",
    "df_combined = np.concatenate([df_train_morgan, df_valid_morgan, df_test_morgan], axis=0)\n",
    "pca = PCA(n_components=reduced_qubits, random_state=53,  svd_solver='full')\n",
    "pca_combined = pca.fit_transform(df_combined)\n",
    "pca_combined = normalize(pca_combined, norm='l2', axis=1)\n",
    "pca_train = pca_combined[:train_num] * np.pi\n",
    "pca_valid = pca_combined[train_num:train_num+valid_num] * np.pi\n",
    "pca_test = pca_combined[train_num+valid_num:] * np.pi\n",
    "\n",
    "\n",
    "newpath = f'/Users/choyboy/Documents/Python/QML/bace_dataset_topol_angle_split/bace_pca_{num_qubits}q{reduced_qubits}'\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "np.savetxt(f'{newpath}/qc_pca_train_classes_bace_{num_qubits}q{reduced_qubits}', train_classes, fmt='%s', delimiter='\\t')\n",
    "np.savetxt(f'{newpath}/qc_pca_train_input_bace_{num_qubits}q{reduced_qubits}', pca_train, delimiter='\\t')\n",
    "np.savetxt(f'{newpath}/qc_pca_valid_classes_bace_{num_qubits}q{reduced_qubits}', valid_classes, fmt='%s', delimiter='\\t')\n",
    "np.savetxt(f'{newpath}/qc_pca_valid_input_bace_{num_qubits}q{reduced_qubits}', pca_valid, delimiter='\\t')\n",
    "np.savetxt(f'{newpath}/qc_pca_test_classes_bace_{num_qubits}q{reduced_qubits}', test_classes, fmt='%s', delimiter='\\t')\n",
    "np.savetxt(f'{newpath}/qc_pca_test_input_bace_{num_qubits}q{reduced_qubits}', pca_test, delimiter='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qc1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
