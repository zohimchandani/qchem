{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from IPython.display import SVG\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import deepchem as dc\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 4096)\n"
     ]
    }
   ],
   "source": [
    "num_qubits = 12\n",
    "fpgen = rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=2**num_qubits)\n",
    "df = pd.read_csv('bace.csv')\n",
    "df_smiles = df['mol'].to_numpy()\n",
    "df_fp = np.zeros([len(df_smiles), 2**num_qubits])\n",
    "df_classes = df['Class'].to_numpy()\n",
    "df_classes = df_classes + 1\n",
    "for i in range(len(df_smiles)):\n",
    "    mol = Chem.MolFromSmiles(df_smiles[i])\n",
    "    fp = fpgen.GetFingerprint(mol)\n",
    "    array = np.zeros((0, ))\n",
    "    DataStructs.ConvertToNumpyArray(fp, array)\n",
    "    df_fp[i] = array\n",
    "unq, count = np.unique(df_fp, axis=0, return_counts=True)\n",
    "repeated_groups = unq[count > 1]\n",
    "print(repeated_groups.shape)\n",
    "# for repeated_group in repeated_groups:\n",
    "#     repeated_idx = np.argwhere(np.all(df_fp == repeated_group, axis=1))\n",
    "#     print(repeated_idx.ravel())\n",
    "\n",
    "dataset = dc.data.DiskDataset.from_numpy(X=df_classes,ids=df_smiles)\n",
    "scaffoldsplitter = dc.splits.ScaffoldSplitter()\n",
    "train, valid, test = scaffoldsplitter.train_valid_test_split(dataset)\n",
    "train_classes = train.X\n",
    "valid_classes = valid.X\n",
    "test_classes = test.X\n",
    "train_smiles = train.ids\n",
    "valid_smiles = valid.ids\n",
    "test_smiles = test.ids\n",
    "train_num = len(train_smiles)\n",
    "valid_num = len(valid_smiles)\n",
    "test_num = len(test_smiles)\n",
    "df_train_fp = np.zeros([train_num, 2**num_qubits])\n",
    "df_valid_fp = np.zeros([valid_num, 2**num_qubits])\n",
    "df_test_fp = np.zeros([test_num, 2**num_qubits])\n",
    "for i in range(train_num):\n",
    "    mol = Chem.MolFromSmiles(train_smiles[i])\n",
    "    fp = fpgen.GetFingerprint(mol)\n",
    "    array = np.zeros((0, ))\n",
    "    DataStructs.ConvertToNumpyArray(fp, array)\n",
    "    df_train_fp[i] = array\n",
    "for i in range(valid_num):\n",
    "    mol = Chem.MolFromSmiles(valid_smiles[i])\n",
    "    fp = fpgen.GetFingerprint(mol)\n",
    "    array = np.zeros((0, ))\n",
    "    DataStructs.ConvertToNumpyArray(fp, array)\n",
    "    df_valid_fp[i] = array\n",
    "for i in range(test_num):\n",
    "    mol = Chem.MolFromSmiles(test_smiles[i])\n",
    "    fp = fpgen.GetFingerprint(mol)\n",
    "    array = np.zeros((0, ))\n",
    "    DataStructs.ConvertToNumpyArray(fp, array)\n",
    "    df_test_fp[i] = array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduced_qubits = 3\n",
    "# df_combined = np.concatenate([df_train_fp, df_valid_fp, df_test_fp], axis=0)\n",
    "# pca = PCA(n_components=2**reduced_qubits)\n",
    "# pca_combined = pca.fit_transform(df_combined)\n",
    "# pca_combined = normalize(pca_combined, norm='l2', axis=1)\n",
    "# pca_train = pca_combined[:train_num]\n",
    "# pca_valid = pca_combined[train_num:train_num+valid_num]\n",
    "# pca_test = pca_combined[train_num+valid_num:]\n",
    "\n",
    "# n = 0\n",
    "# for i in range(len(train_smiles)):\n",
    "#     for j in range(2**reduced_qubits):\n",
    "#         if pca_train[i,j] != 0:\n",
    "#             if n == 0:\n",
    "#                 df_pca_con_train_fp = pca_train[i,j]\n",
    "#                 df_pca_con_train_indices = np.array([i,j], dtype=int)\n",
    "#                 n = n + 1\n",
    "#             else:\n",
    "#                 df_pca_con_train_fp = np.append(df_pca_con_train_fp, pca_train[i,j])\n",
    "#                 df_pca_con_train_indices = np.append(df_pca_con_train_indices, np.array([i,j]))\n",
    "# n = 0\n",
    "# for i in range(len(valid_smiles)):\n",
    "#     for j in range(2**reduced_qubits):\n",
    "#         if pca_valid[i,j] != 0:\n",
    "#             if n == 0:\n",
    "#                 df_pca_con_valid_fp = pca_valid[i,j]\n",
    "#                 df_pca_con_valid_indices = np.array([i,j], dtype=int)\n",
    "#                 n = n + 1\n",
    "#             else:\n",
    "#                 df_pca_con_valid_fp = np.append(df_pca_con_valid_fp, pca_valid[i,j])\n",
    "#                 df_pca_con_valid_indices = np.append(df_pca_con_valid_indices, np.array([i,j]))\n",
    "# n = 0\n",
    "# for i in range(len(test_smiles)):\n",
    "#     for j in range(2**reduced_qubits):\n",
    "#         if pca_test[i,j] != 0:\n",
    "#             if n == 0:\n",
    "#                 df_pca_con_test_fp = pca_test[i,j]\n",
    "#                 df_pca_con_test_indices = np.array([i,j], dtype=int)\n",
    "#                 n = n + 1\n",
    "#             else:\n",
    "#                 df_pca_con_test_fp = np.append(df_pca_con_test_fp, pca_test[i,j])\n",
    "#                 df_pca_con_test_indices = np.append(df_pca_con_test_indices, np.array([i,j]))\n",
    "\n",
    "\n",
    "\n",
    "# df_pca_con_train_fp = df_pca_con_train_fp.T\n",
    "# df_pca_con_valid_fp = df_pca_con_valid_fp.T\n",
    "# df_pca_con_test_fp = df_pca_con_test_fp.T\n",
    "# df_pca_con_train_indices = df_pca_con_train_indices + 1\n",
    "# df_pca_con_valid_indices = df_pca_con_valid_indices + 1\n",
    "# df_pca_con_test_indices = df_pca_con_test_indices + 1\n",
    "# df_pca_new_con_train_indices = np.reshape(df_pca_con_train_indices, (-1,2))\n",
    "# df_pca_new_con_valid_indices = np.reshape(df_pca_con_valid_indices, (-1,2))\n",
    "# df_pca_new_con_test_indices = np.reshape(df_pca_con_test_indices, (-1,2))\n",
    "# df_train_input = np.zeros([len(train_smiles),1])\n",
    "# df_valid_input = np.zeros([len(valid_smiles),1])\n",
    "# df_test_input = np.zeros([len(test_smiles),1])\n",
    "\n",
    "# newpath = f'/home/choyboy/Documents/Python/cuda/bace_dataset_topol_split/bace_pca_{num_qubits}q{reduced_qubits}'\n",
    "# if not os.path.exists(newpath):\n",
    "#     os.makedirs(newpath)\n",
    "\n",
    "# np.savetxt(f'{newpath}/qc_pca_train_initial_bace_{num_qubits}q{reduced_qubits}', df_pca_con_train_fp, delimiter='\\t')\n",
    "# np.savetxt(f'{newpath}/qc_pca_train_initial_index_bace_{num_qubits}q{reduced_qubits}', df_pca_new_con_train_indices.astype(int), fmt='%s', delimiter='\\t')\n",
    "# np.savetxt(f'{newpath}/qc_pca_train_classes_bace_{num_qubits}q{reduced_qubits}', train_classes, fmt='%s', delimiter='\\t')\n",
    "# np.savetxt(f'{newpath}/qc_pca_train_input_bace_{num_qubits}q{reduced_qubits}', df_train_input, delimiter='\\t')\n",
    "# np.savetxt(f'{newpath}/qc_pca_valid_initial_bace_{num_qubits}q{reduced_qubits}', df_pca_con_valid_fp, delimiter='\\t')\n",
    "# np.savetxt(f'{newpath}/qc_pca_valid_initial_index_bace_{num_qubits}q{reduced_qubits}', df_pca_new_con_valid_indices.astype(int), fmt='%s', delimiter='\\t')\n",
    "# np.savetxt(f'{newpath}/qc_pca_valid_classes_bace_{num_qubits}q{reduced_qubits}', valid_classes, fmt='%s', delimiter='\\t')\n",
    "# np.savetxt(f'{newpath}/qc_pca_valid_input_bace_{num_qubits}q{reduced_qubits}', df_valid_input, delimiter='\\t')\n",
    "# np.savetxt(f'{newpath}/qc_pca_test_initial_bace_{num_qubits}q{reduced_qubits}', df_pca_con_test_fp, delimiter='\\t')\n",
    "# np.savetxt(f'{newpath}/qc_pca_test_initial_index_bace_{num_qubits}q{reduced_qubits}', df_pca_new_con_test_indices.astype(int), fmt='%s', delimiter='\\t')\n",
    "# np.savetxt(f'{newpath}/qc_pca_test_classes_bace_{num_qubits}q{reduced_qubits}', test_classes, fmt='%s', delimiter='\\t')\n",
    "# np.savetxt(f'{newpath}/qc_pca_test_input_bace_{num_qubits}q{reduced_qubits}', df_test_input, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_qubits = 2\n",
    "df_combined = np.concatenate([df_train_fp, df_valid_fp, df_test_fp], axis=0)\n",
    "pca = PCA(n_components=reduced_qubits)\n",
    "pca_combined = pca.fit_transform(df_combined)\n",
    "pca_combined = normalize(pca_combined, norm='l2', axis=1)\n",
    "pca_train = pca_combined[:train_num] * np.pi\n",
    "pca_valid = pca_combined[train_num:train_num+valid_num] * np.pi\n",
    "pca_test = pca_combined[train_num+valid_num:] * np.pi\n",
    "\n",
    "\n",
    "newpath = f'/home/choyboy/Documents/Python/cuda/bace_dataset_topol_angle_split/bace_pca_{num_qubits}q{reduced_qubits}'\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "np.savetxt(f'{newpath}/qc_pca_train_classes_bace_{num_qubits}q{reduced_qubits}', train_classes, fmt='%s', delimiter='\\t')\n",
    "np.savetxt(f'{newpath}/qc_pca_train_input_bace_{num_qubits}q{reduced_qubits}', pca_train, delimiter='\\t')\n",
    "np.savetxt(f'{newpath}/qc_pca_valid_classes_bace_{num_qubits}q{reduced_qubits}', valid_classes, fmt='%s', delimiter='\\t')\n",
    "np.savetxt(f'{newpath}/qc_pca_valid_input_bace_{num_qubits}q{reduced_qubits}', pca_valid, delimiter='\\t')\n",
    "np.savetxt(f'{newpath}/qc_pca_test_classes_bace_{num_qubits}q{reduced_qubits}', test_classes, fmt='%s', delimiter='\\t')\n",
    "np.savetxt(f'{newpath}/qc_pca_test_input_bace_{num_qubits}q{reduced_qubits}', pca_test, delimiter='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qc1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
